{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "youtube data\n",
      "------------ \n",
      "Log data\n",
      "\n",
      "\n",
      "connection closed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from Create_Table_queries import *\n",
    "\n",
    "\n",
    "def process_youtubedata_file(cur, filepath): \n",
    "    \"\"\"\n",
    "        This function reads one JSON file and read information of videos and youtuber data and saves into video_data and youtuber_data\n",
    "        Arguments:\n",
    "        cur: Database Cursor\n",
    "        filepath: location of JSON files\n",
    "        Return: None\n",
    "    \"\"\"\n",
    "    # open JSON file\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "    \n",
    "    # ---------insert youtuber record----------\n",
    "    # write your code here that reads youtuber data from JSON file and insert it into Youtubers_dim table \n",
    "\n",
    "    # write your code here\n",
    "    for indx, row in df.iterrows():\n",
    "        youtuber_record = [ row['youtuber_id']['0'],row['youtuber_name']['0'],row['youtuber_location']['0'],row['youtuber_latitude']['0'],row['youtuber_longitude']['0'] ]\n",
    "        #print(youtuber_record)\n",
    "        cur.execute(\"Select count(*) from youtubers_dim where youtuber_Id='\"+str(row['youtuber_id']['0'])+\"';\")\n",
    "        res  = cur.fetchone()\n",
    "        if res[0] == 0:\n",
    "            cur.execute(Youtubers_table_insert, youtuber_record)\n",
    "\n",
    "\n",
    "    # ---------insert video record--------------\n",
    "    # write your code here that reads youtube videos data from JSON file and insert it into Videos_dim table \n",
    "\n",
    "    # write your code here\n",
    "    for indx, row in df.iterrows():\n",
    "        video_record = [ row['video_id']['0'],row['title']['0'],row['youtuber_id']['0'],row['year']['0'],row['duration']['0'] ]\n",
    "        #print(video_record)\n",
    "        cur.execute(\"Select count(*) from videos_dim where video_Id='\"+str(row['video_id']['0'])+\"';\")\n",
    "        res  = cur.fetchone()\n",
    "        if res[0] == 0:\n",
    "            cur.execute(Videos_table_insert, video_record)\n",
    "            \n",
    "\n",
    "\n",
    "def process_log_file(cur, filepath):\n",
    "    \"\"\"\n",
    "        This function reads Log files and reads information of time, user and videoplay data and saves into time, user, videoplay\n",
    "        Arguments:\n",
    "        cur: Database Cursor\n",
    "        filepath: location of Log files\n",
    "        Return: None\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # open log file\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "\n",
    "    # filter by NextVideo action\n",
    "    df = df[(df['page'] == 'NextVideo')]\n",
    "\n",
    "    # convert timestamp column to datetime    \n",
    "    # insert time data records to Time_dim table\n",
    "        # write your code here\n",
    "\n",
    "    for ind, row in df.iterrows():\n",
    "        date = pd.to_datetime(row['ts'], unit='ms').date()\n",
    "        hr = pd.to_datetime(row['ts'], unit='ms').hour\n",
    "        day = pd.to_datetime(row['ts'], unit='ms').dayofyear\n",
    "        week = pd.to_datetime(row['ts'], unit='ms').week\n",
    "        month = pd.to_datetime(row['ts'], unit='ms').month\n",
    "        year = pd.to_datetime(row['ts'], unit='ms').year\n",
    "        week_day = pd.to_datetime(row['ts'], unit='ms').dayofweek\n",
    "        \n",
    "\n",
    "        #print(row)\n",
    "        cur.execute(\"SELECT COUNT(*) FROM TIME_DIM WHERE start_time='\"+str(date)+\"';\")\n",
    "        res = cur.fetchone()\n",
    "        if res[0] == 0:\n",
    "            time_record = [date, hr, day, week, month, year, week_day]\n",
    "            cur.execute(Time_table_insert, time_record)\n",
    "            \n",
    "            \n",
    "    # load user table\n",
    "    \n",
    "    # insert user records into Users_dim table\n",
    "        # write your code here\n",
    "    for ind, row in df.iterrows():\n",
    "        user_record = [ row['userId'], row['firstName'], row['lastName'], row['gender'], row['level']  ]\n",
    "        #print(user_record)\n",
    "        cur.execute(\"Select count(*) from users_dim where user_Id=\"+str(row['userId'])+\";\")\n",
    "        res  = cur.fetchone()\n",
    "        if res[0] == 0:\n",
    "            cur.execute(Users_table_insert, user_record)\n",
    "\n",
    "    # insert Videoplay records in Videoplay_fact table\n",
    "        # write your code here\n",
    "\n",
    "    for ind, row in df.iterrows():\n",
    "        vid_name = list(row['video'])\n",
    "        vid_name = \"\".join([\"''\" if i==\"'\" else i for i in vid_name])\n",
    "\n",
    "        cur.execute(\"SELECT video_id, youtuber_id from videos_dim WHERE title LIKE '%\"+vid_name+\"';\")\n",
    "        video_Id = None\n",
    "        youtuber_Id = None\n",
    "        result_row = cur.fetchone() \n",
    "        if result_row:\n",
    "            video_Id = result_row[0]\n",
    "            youtuber_Id = result_row[1]\n",
    "\n",
    "        vp_record = [ind, pd.to_datetime(row['ts'], unit='ms').date(), row['userId'], row['level'], video_Id , youtuber_Id, row['sessionId'], row['location'] ,row['userAgent']]\n",
    "    \n",
    "        cur.execute(Videoplay_table_insert, vp_record)\n",
    "        \n",
    "\n",
    "def process_data(cur, conn, filepath, func):\n",
    "    \"\"\"\n",
    "        This function get all JSON files in given directory by exploring all sub directories, an++d process all files that were found using the given function.\n",
    "        Example: if I give it the path to youtube_data directory which resides in data folder of this assignment,\n",
    "        and func given is process_youtubedata_file it should get all JSON files in this directories and process each file using process_youtubedata_file function. \n",
    "        Arguments:\n",
    "        cur: Database Cursor\n",
    "        conn: Database\n",
    "        filepath: location of JSON files\n",
    "        func: function to process all files in the directory\n",
    "        Return: None\n",
    "    \"\"\"\n",
    "    for sd,dr, files in os.walk(filepath):\n",
    "        for  file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                func(cur, os.path.join(sd,file) )\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=youtubedb user=postgres password=12345678\")\n",
    "    cur = conn.cursor()\n",
    "    conn.set_session(autocommit=True)\n",
    "    \n",
    "    print(\"youtube data\")\n",
    "    process_data(cur, conn, filepath='data/youtube_data', func=process_youtubedata_file)\n",
    "    print(\"----\"*3,\"\\nLog data\\n\")\n",
    "    process_data(cur, conn, filepath='data/log_data', func=process_log_file)\n",
    "\n",
    "    conn.close()\n",
    "    print(\"\\nconnection closed!\")\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
